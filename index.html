<!DOCTYPE html>
<html lang="en">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">

  <title>AirBass</title>

  <!-- Bootstrap core CSS -->
  <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Custom fonts for this template -->
  <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet">
  <link href="vendor/fontawesome-free/css/all.min.css" rel="stylesheet">

  <!-- Custom styles for this template -->
  <link href="css/resume.min.css" rel="stylesheet">

</head>

<body id="page-top">

  <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
    <a class="navbar-brand js-scroll-trigger" href="#page-top">
      <span class="d-block d-lg-none">AirBass</span>
      <span class="d-none d-lg-block">
        <img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="img/system_profile.jpg" alt="">
      </span>
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav">
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#about">About</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#high-level">High-Level Design</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#in-depth">In-Depth Breakdown</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#results">Results</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#conclusions">Conclusions</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#appendix">Appendix</a>
        </li>
      </ul>
    </div>
  </nav>

  <div class="container-fluid p-0">

    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="about">
      <div class="w-100" style="float:left;">
        <h1 class="mb-0">Air
          <span class="text-primary">Bass</span>
        </h1>
        <div class="subheading mb-5">ECE 4760 Final Project built by:
          <ul>
            <li>Caitlin Stanton (cs968)</li>
            <li>Peter Cook (pac256)</li>
            <li>Jackson Kopitz (jsk363)</li>
          </ul>
        </div>

        <div class="mb-5">
          <h2 class="mb-5">Introduction</h2>
          <div class="resume-content mb-0">
            AirBass is an air bass guitar that allows the user
            to play distinct notes without the added weight and cost of an actual
            bass guitar. It implement various sensors for input to output sound
            that is accurate both in terms of frequency and duration.
          </div>
        </div>
      </div>
      <div class="w-100" style="float:right">
        <img class="img-fluid mx-auto mb-2" src="img/system_profile.jpg" alt="">
      </div>
    </section>

    <hr class="m-0">

    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="high-level">
      <div class="w-100">
        <h2 class="mb-5">High-Level Overview</h2>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0">Societal Impact</h3>
            <p>Our plan for this project is mainly for entertainment purposes,
              and is not dangerous. Nevertheless, we plan to build a user-friendly
              playable instrument that is similar to a bass guitar. As far as we
              know, this is a novel idea that we originated. We should be able
              achieve this goal combining information discussed in previous labs
              with our own ideas. Our plan for implementing this design is
              described in detail in the next section.</p>

            <p>In theory, our design should be relatively inclusive for all
              types of ability. This device is one that can be held like a
              guitar, but can also be placed on a table or the floor to be
              played, meaning that users who can’t hold objects for a long
              time and/or in an upright position can also play. The use of a
              glove fitted with flex sensors will make playing our air guitar
              easier than that of a real guitar since the user does not need to
              make full contact with the strings and their fingertips in order
              to produce a sound. The major prerequisite for our user is that
              they have at least one fully functional hand with a minimum of
              four moveable digits (for each of the four fingers of the glove
              that will be outfitted with flex sensors) and another limb/device
              that they can control to make the “strumming” motion.</p>

            <p>Color and identifying specific shapes/patterns don’t play much of
              a role in our implementation, so those who have color blindness or
              poor eyesight should have a similar experience as those with full
              seeing ability. For full user experience, some hearing ability is
              needed—this doesn’t help with interfacing with the device itself,
              but improves the general functionality of our project as a way to
              practice guitar without physically owning one. Being able to hear
              the synthesized notes will enhance the user’s chances to
              self-correct the placement of their fingers and the timing of their
              strumming so as to play any melodies they choose.</p>

          <p>Our project doesn’t involve any over-air communication, so there
            are no specific IEEE or FCC standards that we must follow.
            Additionally, our use of inputs and outputs that pose little to no
            harm to the user imply that there aren’t any major ANSI, ISO, or
            FDA standards that are applicable. Copyright claims will not be
            much of a concern to our team, as the user will be responsible for
            any melodies they create and how they wish to share them.</p>

        </div>
      </div>

      <div class="resume-item d-flex flex-column flex-md-row justify-content-between">
        <div class="resume-content">
        <h3 class="mb-0">Implementation Overview</h3>
        <p>The slab of wood would be used to mimic the neck of a bass guitar,
          as shown in Figure 1 below. To synthesize the four individual strings,
          we’d align four line sensors parallel to the length of the wood.
          If a finger is placed on one of the “strings”, the line break
          sensor would register this and it will narrow down the range of
          potential frequencies of sound that we’d have to output. The fifth
          line break sensor would be placed farther down on the slab,
          oriented parallel to its length—this would help us add a “strumming”
          functionality to trigger when the notes should actually be played,
          so the user can practice rhythm in addition to playing in tune.</p>

        <p>Line break sensors can only detect if an object has passed between
          the pair, not the location of where the object broke the line.
          Since the positioning of your fingers on each string of a guitar
          is crucial to playing a certain note, we need to analyze what
          finger is being placed on the “string” and at what fret.</p>

        <p>For the latter, to determine at which fret the user is playing,
          we’d use an ultrasonic distance sensor. This sensor would be placed
          at the end of the wood slab and would measure how far down the
          next of the guitar the user’s hand is. This distance data would be
          used to output which fret the user is playing at, based on the
          length of the neck of a guitar and the typical placement of each
          fret. This data, along with knowing which specific "line” was
          broken, will further constrict the span of notes the user is
          attempting to play.</p>

        <p>We’re using a black polyester glove with short flex sensors attached
          to the inside of each finger, as shown in Figure 2. These sensors
          have a resistance of ~10KΩ when at rest and up to ~20KΩ when flexed.
          When the user bends a finger, we determine which finger is bent,
          which line break sensor has been broken, and how far down the
          neck the user’s hand is to determine which note is being played.
          This will also serve as a kind of redundancy check, so that a note
          will only be played both when the string/line is broken and when a
          corresponding finger is bent.</p>

        <p>Because the ultrasonic distance sensor can only measure the closest
          finger to the sensor, the middle finger through pinky finger, if
          flexed, will correspond to the next 3 frets adjacent to the index
          finger.</p>

        <p>Using either additive synthesis or FM modulation, we will produce
          guitar-like sounds, similar to lab 1. We will use the DAC possibly
          fortified/simplified using DMA, the audio jack, and the lab speakers
          to play the music played by the user.</p>

        </div>
      </div>
    </div>
  </section>

  <hr class="m-0">

  <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="in-depth">
    <div class="w-100">
      <h2 class="mb-5">In-Depth Breakdown</h2>

      <h3 class="mb-0">Ultrasonic Distance Sensors</h3>
      <p>On a guitar, the sound of the note being played changes not only based
        on the strings being plucked but also the fingers placed on the frets.</p>

      <img src="img/fretboard_photo.jpeg" alt="" style="display:block; margin-left:auto; margin-right:auto;">

      <p>To determine which of the frets were being placed, we used a
        <a href="https://www.sparkfun.com/products/15569">SparkFun SEN-15569</a>
        ultrasonic distance sensor. The general overview of this sensor is that,
        once triggered, eight 40kHz signals are sent out to potentially reflect
        off of any objects that are in front of the sensor. If a signal is
        reflected back, then the outputted signal (aka echo) is equal to the
        difference in time between the pulse and the received pulse. For this
        to be incorporated into our prototype, we wanted to use the ultrasonic
        distance sensor to detect the distance from the top of the neck of our
        bass guitar to the user’s playing hand. This result would then be used to
        determine on which fret the first finger was placed.  This sensor needed
        a 5V power supply, which we were able to provide using the MCU Vin pin.
        There was no need for a voltage regulator because we knew our final
        prototype would use the 5V power adaptor. In the case of the PIC32 being
        powered with a separate battery, a voltage regulator would be needed to
        keep the sensor powered at a steady 5V with no sharp increases in voltage
        or spikes in current.</p>

      <p>The implementation of this general process can be seen in the protothreads
        function <code>protothreads_distance</code>. The trigger—which, when set,
        would start the series of pulses to read the distance to an object—was
        connected to MCU pin RPA1, which had been enabled as an output. As
        long as the <code>define use_uart_serial</code> statement was commented
        out in the <code>config_1_3_2.h</code> file, there was no other use
        for this pin, and therefore nothing preventing us from sending the
        trigger signal on it. Pin A1 was set high for one millisecond and
        then cleared. The minimum length of time that A1 needed to be set for
        was 10 microseconds, so the one millisecond delay was reasonable.</p>

      <p>The actual reading from the echo signal was done using an input capture
        on MCU pin RB13. An input capture is a hardware timer, where the time of
        specified edge of a signal received by the input capture pin is measured.
        This provides an extremely accurate timing of events, up to within a
        cycle of the signal edge occuring. We decided to use this hardware timer,
        rather than reading the signal on a digital GPIO pin and using a counter
        variable, because it wasn’t as likely to hang. If we had used the GPIO
        pin and software timing route, our logic for the protothread would’ve
        kept it stuck waiting for a pulse back, thereby preventing us from
        setting a new trigger signal.</p>

      <p>The code written to initialize the input capture can be found between
        lines 521 and 533 in <code>main()</code>. The input capture required a
        timer, as it would be used to keep track of the edge of the inputted
        signal. For our program, we used timer3 for this purpose, and initialized
        it to take continuous readings and have a prescaler value of 32. The
        prescaler prevented the results from the input capture to not overflow.
        An additional precaution for this was declaring the distance readings as
        unsigned integers.</p>

      <p>Next we configured capture1 to be connected to an interrupt service
        routine (ISR) that would read integer timer values on <code>timer3</code> due to the
        falling edge of a signal. Using an ISR prevented any other parts of the
        program from overriding the distance sensor so that we would get the most
        accurate readings from the input capture. Taking values from the falling
        edge of the signal would only provide a distance once the entirety of a
        returned pulse had been received. Lastly, MCU pin RPB13 was connected to
        <code>capture1</code> using PPS.</p>

      <p>Since the ISR would preempt any other functions that were running at
        the time, we took care to make the ISR as brief as possible to not let
        any other functions hang. This meant that the ISR only ran two lines of
        code: <code>mIC1ReadCapture()</code> to save the value off of <code>timer3</code>
        when the reflected pulse was received; and <code>mIC1ClearIntFlag()</code>
        to clear the timer interrupt flag.</p>

      <p>Within <code>protothreads_distance</code>, after the trigger signal
        was set for one millisecond, the interrupt flag for the <code>capture1</code>
        ISR was cleared and <code>timer3</code> was set to zero. The first function
        was performed so that <code>capture1</code> would be accurately updated
        with the most recent falling edge. The second call was made so that no
        additional arithmetic had to be performed to find the length of time
        between the 40kHz pulses and the reflected pulse.</p>

      <p>Once the ISR read from the input capture pin, an infinite impulse
        response filter was applied to make the value more reliably accurate,
        otherwise we noticed a large amount of fluctuation. The averaging was
        done over the four most recent input capture values, which were saved
        into a circular buffer whose starting and ending indexes were constantly
        updated. The variable distance would be incremented by the difference
        between the most recent reading and the least recent reading in this
        circular buffer.</p>

      <p>When reading the echo pin from the sensor on the oscilloscope, we noted
        slight noise. The theory behind this is that it’s caused by the
        switching within the sensor itself, most likely due to the MHz clock.
        At first, we placed an electrolytic capacitor between power and ground.
        Although it did reduce noise, it has an internal frequency of around 100kHz,
        leading to slow switching rates. Ultimately, we built a low pass voltage
        divider filter, as shown below. We made sure to use a ceramic capacitor
        as it has a faster internal frequency, and therefore our circuit would
        have a faster response.</p>

      <img src="img/distance_circuit.png" alt="" style="display:block; margin-left:auto; margin-right:auto;">

      <p>Now that the distance reading was averaged, it had to be calibrated.
        After working with the distance sensor a bit, we noticed that the distance
        values changed based on the positioning of the object it was looking at.
        In the case of our prototype, this object was the side of a hand, which
        is extremely hard to maintain in a static position with the same amount
        of surface area being presented, despite the strings and/or frets it’s at.
        To remedy this, we spent a decent amount of time measuring the distance
        sensor’s output across various combinations of depressed strings and frets.
        The calibration data for this can be seen in the table below:</p>

      <table></table>

      <p>These distance ranges were then used in a series of conditional statements
      to set the fret for each individual string being depressed: <code>e_fret</code>,
      <code>a_fret</code>, <code>d_fret</code>, and <code>g_fret</code>. If none
      of the four strings were depressed (meaning that zero of them had their
      beam break broken), then all four fret variables were set to zero,
      indicating an open string. If at least one of the four strings were
      being depressed, then the fret variables were set if 1) that specific
      string was depressed and 2) the distance sensor reading was within the range
      for that fret. Since the farther frets would have larger distance readings,
      those ranges were used in earlier if statements. The reasoning behind
      this was that it was that a higher distance range was easier to achieve,
      and so by putting these ranges earlier, it ensured that lower distance
      readings wouldn’t accidentally be set to the wrong fret. For example,
      on the E string, the first fret was expecting a distance reading of
      less than 120—if the logic for setting the first fret came before the
      logic for setting the second fret, then the second fret would be the
      final (yet wrong) result.</p>

      <p>Cascading ranges (which checked to see if <code>distance</code> was less than the
      calibration value) were used rather than constricted ranges (which checked
      to see if <code>distance</code> was both greater than a calibration value and less
      than another calibration value). This was because of the variation between
      the boundaries of each fret. We felt that using cascading ranges would
      cut down on the amount of accidental fret switching due to the ultrasonic
      distance sensor not being as precise as possible.</p>

      <p>Although the distance sensor did perform as wanted, the calibration of the
      sensor could’ve been improved. The majority of our work with the sensor was
      finding the distance values at each fret and changing those values as we
      recognized the natural way a user would hold our prototype. As mentioned
      earlier, the human hand isn’t a flat, regular surface, so even tilting the
      playing hand slightly would affect the distance reading. Although we tried
      to alleviate this by extending the distance ranges for each fret, our final
      prototype did experience slight toggling between note frequency when fingers
      were placed on the boundary between two frets. A fix for this would’ve been
      adding multiple distance sensors, perhaps one for each string (to accommodate
      for the different readings at each string position) or a single one at the
      other end of the neck of the guitar (for calibrating against the difference
      of the two recorded values).</p>

      <h3 class="mb-0">Flex Sensors</h3>

      <p>In order to accurately determine when individual strings of our bass
        are “plucked,” we used the <a href="https://www.sparkfun.com/products/10264">
        SparkFun SEN-10264</a> two-inch flex sensors. At a high level, the idea
        for implementing these sensors is that we could use the variable
        resistance across the terminals in a voltage divider circuit, so that
        the output voltage could be used to determine which of four strings is
        being plucked (one string corresponding to each flex sensor). The result
        is that we can accurately pluck open strings, start and stop playing
        individual notes independent of the fret/finger position decided by
        the beam breaks and distance sensor, as would be the case in a real
        bass. To further liken the experience of our AirBass to an actual bass
        guitar, we have the flex sensors attached to the inner palm of a glove
        so that the integrated system can register moving a finger while wearing
        the glove, and begin playing the desired note. The final setup is shown below.</p>

      <img src="img/flex_sensor_setup.jpg" alt="" style="display:block; margin-left:auto; margin-right:auto;">
      <p><i>Figure XXX: Final setup for flex sensor glove - pinky, ring, middle,
         and pointer finger control plucking of the G, D, A, E strings, respectively.</i></p>

      <p>To construct our voltage divider (to divide the supply Vcc = 3.3V when
        flexing the device), we first measured the resistance of the flex sensors.
         We found that they have an unflexed resistance of about 30K, which
         approximately linearly increases to about 100K when fully flexed.
         Noting these values, we decided to put the flex sensor in parallel to
         the output and chose a series resistance Re = 50K to Vcc, since this
         gives an output voltage that ranges between ~1.2V and ~2.2V, which is
         appropriate for 3.3V level logic.</p>

     <p><i>Figure XXX: Voltage divider used for reading a varying output voltage
       from our flex sensor.</i></p>

     <p>Next, we noticed that for our final implementation we only cared about a
       true/false value answering the question “is string i being plucked?” for
       each of the four strings i. Accordingly, we tried a few circuits to convert
       this analog output voltage (ranging ~1.2V to ~2.2V) to a digital high or
       low signal. Initially, we attempted to use the voltage divider output for
       triggering an open drain FET (i.e. with the source grounded and the gate
       this voltage divider output), since then we could easily pull the output
       voltage up to the MCU’s power rail. We abandoned this approach for two
       reasons: (1) the FET took relatively long to trigger and we saw an approximately
       exponential rise time on the oscilloscope, which is no-nideal here since
       we need a fast response to play the bass realistically, and (2) to avoid
       any mechanical effects of the sensor and make it “easier” to pluck the
       strings, we decided we needed some hysteresis in our trigger circuit so
       that a user would have to intentionally unflex a finger to stop plucking
       the string rather than this kind of event happening accidentally. Hence,
       we used a Schmitt trigger which is shown below.</p>


    <p><i>Figure XXX: Full flex sensor, with MCP6242 amplifier, and resistance
      values R1 = 12K, R2 = 15K, R3 = 30K, RE = 50K.</i></p>

    <p>As shown above, the output of our voltage divider is the input voltage
      for an inverting Schmitt trigger, on the inverting terminal of the amplifier.
      The resulting circuit, with resistance values as stated above, has a high
      threshold of 2.1V and a low threshold of 1.5V. That is, when the output is
      currently low (sitting at 0V) and the input (V-) to the inverting terminal
      goes above 1.5V, the circuit triggers and brings the output to 3.3V. When
      the output is currently high and the input goes below 2.1V, the circuit
      triggers and brings the output to 0V. Since our voltage divider ranges over
      values ~1.2V to ~2.2V, these thresholds are within our capabilities and we
      effectively have an integrated circuit whose output will be digital high
      when the sensor is flexed and low when it is not flexed (with some hysteresis).
      For our final design, we have four of this circuit (one for each string/flex
      sensor) and in practice, we saw that while this did work reasonably well,
      for some of the sensors unflexing to go back below the high threshold was a
      little difficult. Not all of the sensors have the same range of resistances,
      and for one sensor in particular it was difficult to make the digital high
      output go low again, while it worked like a charm for the others.</p>

    <img src="img/flex_sensor_protoboard.jpg" alt="" style="display:block; margin-left:auto; margin-right:auto;">
    <p><i>Figure XXX: Completed circuit used in demo, with four duplicated Schmitt
      triggers near the top of the image.</i></p>

    <p>To read these outputs, we used MCU pins Z4,Z5,Z6,Z7 on the port expander.
      Similar to reading the beam break inputs, in an SPI critical section we
      read the current Z port into a local variable and outside this critical
      section checked individual bits of the word to determine which flex sensors
      were flexed and which were not. We set integers <code>e_pluck</code>,
      <code>a_pluck</code>, <code>d_pluck</code>, and <code>g_pluck</code> to 0
      or -1 depending on which bits of the word were high to indicate whether
      or not a sensor was being flexed. Additionally, we have boolean state
      variables <code>string_depressed</code> and <code>prev_string_depressed</code>
      to indicate whether or not one of the four strings is currently being
      plucked or was being plucked in the previous read to the Z port. Then,
      if we transition from nothing plucked to some string being plucked,
      we start timing a new note/amplitude envelope by setting <code>current_amplitude</code>
      to 0 and curr_attack_time to 0 as well - in the audio ISR, this is handled
      so that during an attack, the amplitude linearly increases to
      <code>max_amplitude</code>. Similarly, if we transition from something
      plucked to nothing being plucked, we set <code>current_amplitude</code> to
      <code>max_amplitude</code> and <code>curr_decay_time</code> to 0 - this
      initialization causes the ISR to linearly decrease the amplitude to 0 over a
      full <code>decay_time</code>. The result of this logic, further explained
      in the next section, gives the ability to play sustained notes with the
      attack and decay part of the envelope so that it sounds less harsh and
      ideally more like an actual bass.</p>

    </div>
  </section>

    <hr class="m-0">

    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="interests">
      <div class="w-100">
        <h2 class="mb-5">Interests</h2>
        </div>
    </section>

    <hr class="m-0">

    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="awards">
      <div class="w-100">

      </div>
    </section>

  </div>

  <!-- Bootstrap core JavaScript -->
  <script src="vendor/jquery/jquery.min.js"></script>
  <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

  <!-- Plugin JavaScript -->
  <script src="vendor/jquery-easing/jquery.easing.min.js"></script>

  <!-- Custom scripts for this template -->
  <script src="js/resume.min.js"></script>

</body>

</html>
